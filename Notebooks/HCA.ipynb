{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a6a57d",
   "metadata": {},
   "source": [
    "# Hierarchical Cluster Analysis (HCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4867bf-be7a-488e-95a4-a3bd54f8c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Hierarchical Cluster Analysis (HCA)\n",
    "\n",
    "## Introduction\n",
    "Hierarchical Cluster Analysis (HCA) is a method for grouping similar objects into clusters.\n",
    "Unlike flat clustering (e.g., k-means), HCA builds a hierarchy of clusters.\n",
    "There are two main types of hierarchical clustering:\n",
    "\n",
    "1. **Agglomerative (bottom-up)**: Each data point starts as its own cluster, and clusters are merged iteratively.\n",
    "2. **Divisive (top-down)**: All data points start in one cluster, and clusters are split iteratively.\n",
    "\n",
    "This notebook will focus on agglomerative clustering using the **average linkage** method.\n",
    "\n",
    "## Steps of HCA\n",
    "1. Compute the pairwise distances between all points.\n",
    "2. Identify the two closest clusters and merge them.\n",
    "3. Update the distance matrix.\n",
    "4. Repeat steps 2 and 3 until all points are in one cluster.\n",
    "5. Represent the results using a **dendrogram**.\n",
    "\"\"\"\n",
    "\n",
    "using Random, Clustering, Distances, Plots\n",
    "\n",
    "\"\"\"\n",
    "## 1. Generating Data\n",
    "We generate two distinct clusters of data points to illustrate HCA.\n",
    "\"\"\"\n",
    "\n",
    "Random.seed!(42)\n",
    "X = vcat(rand(5, 2) .+ 1, rand(5, 2) .+ 4)  # Two distinct clusters\n",
    "\n",
    "\"\"\"\n",
    "## 2. Computing Pairwise Distances\n",
    "HCA relies on a distance matrix that quantifies the similarity between points.\n",
    "We use **Euclidean distance** to measure the distance between data points.\n",
    "\"\"\"\n",
    "\n",
    "dist_matrix = pairwise(Euclidean(), X', dims=2)\n",
    "\n",
    "display(dist_matrix)  # Show distance matrix\n",
    "\n",
    "\"\"\"\n",
    "## 3. Performing Hierarchical Clustering\n",
    "We use **average linkage**, which calculates the average distance between elements in different clusters.\n",
    "Other linkage methods include:\n",
    "- **Single linkage**: Distance between the closest points of two clusters.\n",
    "- **Complete linkage**: Distance between the farthest points of two clusters.\n",
    "- **Centroid linkage**: Distance between the centroids of two clusters.\n",
    "\"\"\"\n",
    "\n",
    "linkage = hclust(dist_matrix, linkage=:average)\n",
    "\n",
    "\"\"\"\n",
    "## 4. Visualizing the Dendrogram\n",
    "A dendrogram represents the hierarchical structure of clusters.\n",
    "By cutting the dendrogram at a specific height, we can choose the number of clusters.\n",
    "\"\"\"\n",
    "\n",
    "plot(linkage, xticks=1:size(X,1), title=\"Hierarchical Clustering Dendrogram\", xlabel=\"Data Points\", ylabel=\"Distance\")\n",
    "\n",
    "\"\"\"\n",
    "## 5. Additional Examples\n",
    "To further explore HCA, we generate different datasets and apply hierarchical clustering using various linkage methods.\n",
    "\"\"\"\n",
    "\n",
    "# Example 1: Clustering a new dataset with different distributions\n",
    "Random.seed!(100)\n",
    "Y = vcat(randn(5, 2) .+ 3, randn(5, 2) .- 3)\n",
    "dist_matrix_Y = pairwise(Euclidean(), Y', dims=2)\n",
    "linkage_Y = hclust(dist_matrix_Y, linkage=:single)\n",
    "plot(linkage_Y, xticks=1:size(Y,1), title=\"HCA with Single Linkage\", xlabel=\"Data Points\", ylabel=\"Distance\")\n",
    "\n",
    "# Example 2: Applying HCA to a more complex dataset\n",
    "Z = rand(15, 2) * 10\n",
    "dist_matrix_Z = pairwise(Euclidean(), Z', dims=2)\n",
    "linkage_Z = hclust(dist_matrix_Z, linkage=:complete)\n",
    "plot(linkage_Z, xticks=1:size(Z,1), title=\"HCA with Complete Linkage\", xlabel=\"Data Points\", ylabel=\"Distance\")\n",
    "\n",
    "\"\"\"\n",
    "## 6. Exercises\n",
    "Try the following exercises to reinforce your understanding of hierarchical clustering.\n",
    "\n",
    "### Exercise 1: Implement Custom Clustering Function\n",
    "Modify the function to test different linkage methods (e.g., `:single`, `:complete`, `:ward`).\n",
    "\n",
    "### Exercise 2: Generate a Larger Dataset\n",
    "Create a dataset with 50 points and apply hierarchical clustering. Visualize the results.\n",
    "\n",
    "### Exercise 3: Experiment with Different Distance Metrics\n",
    "Modify the distance metric to use **Manhattan** distance instead of Euclidean. Compare the dendrograms.\n",
    "\n",
    "### Exercise 4: Cut the Dendrogram at a Fixed Height\n",
    "Write a function to extract cluster assignments by cutting the dendrogram at a predefined distance threshold.\n",
    "\"\"\"\n",
    "\n",
    "# Solutions\n",
    "\n",
    "\"\"\"\n",
    "## Solution to Exercise 1\n",
    "Modify the function to allow different linkage methods.\n",
    "\"\"\"\n",
    "\n",
    "function hierarchical_clustering(points, method=:average)\n",
    "    return hclust(pairwise(Euclidean(), points', dims=2), linkage=method)\n",
    "end\n",
    "\n",
    "# Example usage\n",
    "dendrogram = hierarchical_clustering(X, :complete)\n",
    "plot(dendrogram)\n",
    "\n",
    "\"\"\"\n",
    "## Solution to Exercise 2\n",
    "Generate a larger dataset and apply clustering.\n",
    "\"\"\"\n",
    "\n",
    "Random.seed!(123)\n",
    "large_X = rand(50, 2) * 10\n",
    "dist_large = pairwise(Euclidean(), large_X', dims=2)\n",
    "linkage_large = hclust(dist_large, linkage=:average)\n",
    "plot(linkage_large, xticks=1:size(large_X,1), title=\"HCA on Large Dataset\", xlabel=\"Data Points\", ylabel=\"Distance\")\n",
    "\n",
    "\"\"\"\n",
    "## Solution to Exercise 3\n",
    "Use Manhattan distance instead of Euclidean.\n",
    "\"\"\"\n",
    "\n",
    "dist_manhattan = pairwise(Cityblock(), X', dims=2)\n",
    "linkage_manhattan = hclust(dist_manhattan, linkage=:average)\n",
    "plot(linkage_manhattan, xticks=1:size(X,1), title=\"HCA with Manhattan Distance\", xlabel=\"Data Points\", ylabel=\"Distance\")\n",
    "\n",
    "\"\"\"\n",
    "## Solution to Exercise 4\n",
    "Extract clusters by cutting the dendrogram at a threshold.\n",
    "\"\"\"\n",
    "\n",
    "function cut_dendrogram(linkage, threshold)\n",
    "    return cutree(linkage, h=threshold)\n",
    "end\n",
    "\n",
    "clusters = cut_dendrogram(linkage, 1.5)\n",
    "println(\"Cluster Assignments:\", clusters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.6",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
